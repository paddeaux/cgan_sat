{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code for the cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "def celeb_label_transform(desired_attr):\n",
    "    \"\"\"\n",
    "    Pass in a the names of all the attributes that you want\n",
    "    \"\"\"\n",
    "\n",
    "    file = open('C:/Users/Paddy/CRT/Github/input/CelebA/list_attr_celeba.csv').read().split()\n",
    "    attr_names = file[0].split(',')\n",
    "    file = file[1:]\n",
    "    \n",
    "    def transform(idx):\n",
    "        attr = torch.tensor([int(entry) for entry in file[idx].split(',')[1:]])\n",
    "        mask = [attr_names[1:][i] in desired_attr for i in range(len(attr))]\n",
    "        masked = attr[mask]\n",
    "        return torch.relu(masked).float()\n",
    "    return transform\n",
    "\n",
    "file = open('C:/Users/Paddy/CRT/Github/input/CelebA/list_attr_celeba.csv').read().split()\n",
    "attr_names = file[0].split(',')\n",
    "\n",
    "bald_transform = celeb_label_transform(\"Bald\")\n",
    "bald_transform(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "targ_dir = 'C:/Users/Paddy/CRT/Github/input/SEN12MS/'\n",
    "filenames = list(pathlib.Path(targ_dir).glob(\"*/*/*.tif\"))\n",
    "\n",
    "# dictionary of lists\n",
    "dict = {'name': filenames}\n",
    "     \n",
    "df = pd.DataFrame(filenames)\n",
    "     \n",
    "# saving the dataframe\n",
    "df.to_csv('sen12_filenames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def sen12_label_transform(desired_season):\n",
    "    \"\"\"\n",
    "    Pass in a the names of all the attributes that you want\n",
    "    \"\"\"\n",
    "\n",
    "    file = open('C:/Users/Paddy/CRT/Github/input/SEN12MS/seasons_labeled_spring.csv').read().split()\n",
    "    season_names = file[0].split(',')\n",
    "    file = file[1:]\n",
    "    \n",
    "    def transform(idx):\n",
    "        season = torch.tensor([int(entry) for entry in file[idx].split(',')[1:]])\n",
    "        mask = [season_names[1:][i] in desired_season for i in range(len(season))]\n",
    "        masked = season[mask]\n",
    "        return torch.relu(masked).float()\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data...\n",
      "Saved.\n",
      "                           scene  spring  summer  fall  winter\n",
      "0  ROIs1158_spring_s2_1_p100.tif      -1      -1     1      -1\n",
      "1  ROIs1158_spring_s2_1_p101.tif      -1      -1     1      -1\n",
      "2  ROIs1158_spring_s2_1_p102.tif      -1      -1     1      -1\n",
      "3  ROIs1158_spring_s2_1_p103.tif      -1      -1     1      -1\n",
      "4  ROIs1158_spring_s2_1_p104.tif      -1      -1     1      -1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"C:/Users/Paddy/CRT/Github/input/SEN12MS/\"\n",
    "filenames = list(pathlib.Path(path).glob(\"*/*/*.tif\"))\n",
    "\n",
    "path = \"C:/Users/Paddy/CRT/Github/input/SEN12MS/ROIs1158_spring\"\n",
    "# s1 = fall, s6 = spring\n",
    "\n",
    "foldernames = list(pathlib.Path(path).glob(\"*/\"))\n",
    "\n",
    "seasons_original = pd.read_csv('C:/Users/Paddy/CRT/Github/input/SEN12MS/seasons_spring.csv')\n",
    "\n",
    "seasons = []\n",
    "filenames = []\n",
    "\n",
    "for folder in foldernames:\n",
    "    for file in list(pathlib.Path(folder).glob(\"*.tif\")):\n",
    "        season_ref = \"_\".join(os.path.basename(file).split(\"_\")[0:4])\n",
    "        season = seasons_original.loc[seasons_original[\"scene\"] == season_ref][\"true_season\"]\n",
    "        filenames.append(os.path.basename(file))\n",
    "        seasons.append(season.item())\n",
    "\n",
    "spring = [1 if x == 'spring' else -1 for x in seasons]\n",
    "summer = [1 if x == 'summer' else -1 for x in seasons]\n",
    "fall = [1 if x == 'fall' else -1 for x in seasons]\n",
    "winter = [1 if x == 'winter' else -1 for x in seasons]\n",
    "\n",
    "df = pd.DataFrame(zip(filenames, spring, summer, fall, winter), columns=['scene','spring', 'summer', 'fall', 'winter'])\n",
    "\n",
    "print(\"Saving data...\")\n",
    "df.to_csv(\"seasons_labeled_spring.csv\", index=False)\n",
    "print(\"Saved.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paddy\\CRT\\Github\\input\\SEN12MS\\ROIs1158_spring\\s2_1\\ROIs1158_spring_s2_1_p100.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"C:/Users/Paddy/CRT/Github/input/SEN12MS/\"\n",
    "filenames = list(pathlib.Path(path).glob(\"*/*/*.tif\"))\n",
    "\n",
    "print(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CelebA Input dimenstion: tensor([[[ 0.8648,  1.0000,  1.0000,  ...,  0.8479,  0.9312,  0.8261],\n",
      "         [ 1.0000,  1.0000,  0.8706,  ...,  1.0000,  1.0000,  0.9656],\n",
      "         [ 0.9470,  0.9622,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         ...,\n",
      "         [ 0.1515,  0.3773,  0.5001,  ...,  0.4716,  0.3428,  0.1306],\n",
      "         [ 0.2813,  0.3296,  0.4257,  ...,  0.4941,  0.4790,  0.3756],\n",
      "         [ 0.3725,  0.4545,  0.3997,  ...,  0.5082,  0.5082,  0.6464]],\n",
      "\n",
      "        [[ 0.6321,  0.8289,  0.8662,  ...,  1.0000,  0.9756,  0.9149],\n",
      "         [ 0.7770,  0.9125,  0.7045,  ...,  0.9733,  0.9010,  1.0000],\n",
      "         [ 1.0000,  0.8156,  0.7264,  ...,  0.8327,  0.8453,  0.8458],\n",
      "         ...,\n",
      "         [-0.2444, -0.1075, -0.1685,  ..., -0.1184, -0.0758, -0.0397],\n",
      "         [-0.1962, -0.3074, -0.1081,  ..., -0.0409,  0.0083, -0.0622],\n",
      "         [-0.0560, -0.1942, -0.0068,  ...,  0.0481,  0.0845,  0.1234]],\n",
      "\n",
      "        [[ 0.8608,  0.5511,  0.4250,  ...,  0.8921,  0.5854,  0.8252],\n",
      "         [ 0.7108,  0.5955,  0.5525,  ...,  0.8132,  0.9381,  0.9599],\n",
      "         [ 0.4664,  0.5827,  0.5734,  ...,  0.8500,  1.0000,  0.7037],\n",
      "         ...,\n",
      "         [-0.7004, -0.5326, -0.4260,  ..., -0.3911, -0.4314, -0.3845],\n",
      "         [-0.4733, -0.5528, -0.4097,  ..., -0.1726, -0.1672, -0.3231],\n",
      "         [-0.5716, -0.4721, -0.3719,  ..., -0.2088, -0.1484,  0.0107]]])\n",
      "Max =  torch.float32\n",
      "Min =  torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from model import *\n",
    "from transforms import *\n",
    "from training_loop import *\n",
    "from celeba_data import *\n",
    "from sen12_data import *\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import argparse\n",
    "from torchinfo import summary\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "topn = 1\n",
    "checkpoint_dir = os.path.join(os.path.dirname(os.getcwd()), \"checkpoints\")\n",
    "name = 'sen12_cgan_test'\n",
    "batch_size = 32\n",
    "gen_steps = 1\n",
    "disc_steps = 1\n",
    "epochs = 1\n",
    "img_size = 256\n",
    "lr = 0.0002\n",
    "beta = 0.5\n",
    "desired_season = ['fall']\n",
    "desired_attr = ['Young']\n",
    "label_size = len(desired_season)\n",
    "data_source = \"C:/Users/Paddy/CRT/Github/input/SEN12MS\"\n",
    "#data_source = \"C:/Users/Paddy/CRT/Github/input/sen12_overfit/ROIs1158_spring_s2_1_p30.tif\"\n",
    "source_labels = \"C:/Users/Paddy/CRT/Github/input/SEN12MS/seasons_labeled_spring.csv\"\n",
    "#source_labels = \"C:/Users/Paddy/CRT/Github/input/sen12_overfit/seasons_labeled_overfit.csv\"\n",
    "bands = \"rgb\" # or \"rgb\"\n",
    "img_channels = 3\n",
    "\n",
    "transform_sen = transforms.Compose(\n",
    "[\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((img_size,img_size),antialias=False),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Normalize([0.5 for _ in range(img_channels)],[0.5 for _ in range(img_channels)])\n",
    "])\n",
    "anntransform_celeb = celeb_label_transform(desired_attr)\n",
    "anntransform_sen12 = sen12_label_transform(source_labels, desired_season)\n",
    "anntransform_sen12_overfit = sen12_overfit_label_transform(source_labels, desired_season)\n",
    "anntransform_celeb_overfit = celeb_label_transform_overfit(desired_attr)\n",
    "\n",
    "imgtransform = BasicImageCropTransform(size = (img_size, img_size), scale = (1, 2))\n",
    "\n",
    "dataset_sen12 = SEN12MS(data_source, transform_sen, anntransform_sen12, \"rgb\")\n",
    "dataset_sen12_overfit = SEN12MS_overfit(data_source, transform_sen, anntransform_sen12_overfit, \"rgb\", 200000)\n",
    "dataset_celeba = CelebDS(imgtransform, anntransform_celeb)\n",
    "dataset_celeba_overfit = CelebDS_overfit(imgtransform, anntransform_celeb_overfit, 50000)\n",
    "\n",
    "first_celeb = dataset_celeba[0][0]\n",
    "first_sen12 = dataset_sen12[0][0]\n",
    "\n",
    "print(\"CelebA Input dimenstion:\", first_celeb)\n",
    "print(\"Max = \", torch.max(first_celeb).dtype)\n",
    "print(\"Min = \", torch.min(first_celeb).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sen12 Input dimenstion: torch.Size([256, 256])\n",
      "Max =  tensor(1.)\n",
      "Min =  tensor(-1.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sen12 Input dimenstion:\", first_sen12)\n",
    "print(\"Max = \", torch.max(first_sen12))\n",
    "print(\"Min = \", torch.min(first_sen12))\n",
    "#print(\"Sen12MS Input dimenstion:\", dataset_sen12[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
